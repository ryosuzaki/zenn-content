---
title: "統計検定準1級 ワークブック 補助資料集" # 記事のタイトル
emoji: "😸" # アイキャッチとして使われる絵文字（1文字だけ）
type: "tech" # tech: 技術記事 / idea: アイデア記事
topics: ["統計学","統計検定","準1級"] # タグ。["markdown", "rust", "aws"]のように指定する
published: false # 公開設定（falseにすると下書き）
---
統計検定準1級対応のワークブック^[https://www.amazon.co.jp/%E6%97%A5%E6%9C%AC%E7%B5%B1%E8%A8%88%E5%AD%A6%E4%BC%9A%E5%85%AC%E5%BC%8F%E8%AA%8D%E5%AE%9A-%E7%B5%B1%E8%A8%88%E6%A4%9C%E5%AE%9A%E6%BA%961%E7%B4%9A%E5%AF%BE%E5%BF%9C-%E7%B5%B1%E8%A8%88%E5%AD%A6%E5%AE%9F%E8%B7%B5%E3%83%AF%E3%83%BC%E3%82%AF%E3%83%96%E3%83%83%E3%82%AF-%E6%97%A5%E6%9C%AC%E7%B5%B1%E8%A8%88%E5%AD%A6%E4%BC%9A/dp/478060852X]は網羅性は高いですが、かなり分かりにくいです。そのため、色々なサイトでそれを補完する必要があるのですが、それを纏めたサイトで十分なものはありません（多分）。

よって、準1級合格を目指す人が協力して高品質な補助資料集を作れる場を、zennのgithub連携を利用して作ってみました。
勉強中の方は是非、参考になったURLを追加してみてください。

# 協力方法
まず、githubアカウントを持ってない方はアカウントを作成して、

https://github.com/signup?ref_cta=Sign+up&ref_loc=header+logged+out&ref_page=%2F&source=header-home

次に下のページにアクセスして、

https://github.com/ryosuzaki/zenn-content/edit/main/articles/718fd8051b40a6.md

ペンボタン（Fork this repository and edit the file）をクリック

![image](https://github.com/user-attachments/assets/2d8a94df-7c25-4346-aa8f-cec4e8c9d6a2)

そうしたら編集画面が出てくるので、ここで変更。

![image](https://github.com/user-attachments/assets/6265d26d-5978-4d3b-a965-0cc1b24f0fb7)

変更が終わったら、Commit changes... ボタンを押して

![image](https://github.com/user-attachments/assets/48ad4ba0-11c7-4847-aded-41f75c473db1)

Extended descriptionに何を変更したかを書いたら、Propose Changesをクリックして完了。

![image](https://github.com/user-attachments/assets/7f79334d-ad0d-44f7-bdf5-793f24e3d792)

できるだけ早く対応します。難しくなってきたら権限委譲します。

# 参考になる受験記
https://zenn.dev/dlbsabu/articles/5300da50921070
https://qiita.com/tutututututu/items/0c745ff9b5ed175ff8bc
https://mimikousi.com/statistical-certificate-pre1/

# 1.事象と確率
大体2級で触れた内容がほとんどなので、チートシートを読めば十分だと思います。
https://toketarou.com/quasi_1_cheatsheet/#toc1
# 2.確率分布と母関数
母関数は、普通に平均、分散求めるのでも良くない？って感じですが、深く考えずに問題だけでも解けるようにしましょう。
この後も繰り返し扱うので、完璧にする必要はないです。
確率母関数は離散型分布、モーメント母関数は連続型分布でよく使うのと、何の期待値かを覚えればまずは十分です。
https://bellcurve.jp/statistics/course/23841.html


# 3.分布と特性値
## 色々な平均
データの平均を取る時に常に期待値の求め方がいいとは限りません。次のような平均を使い分けできるようにしましょう。
- 加重平均^[https://gmo-research.jp/research-column/weighted-average]：商品1つに払われた平均金額(全体に支払われた金額/売れた商品個数)
- 幾何平均^[https://atmarkit.itmedia.co.jp/ait/articles/2311/01/nAews018.html#:~:text=%E6%95%B0%E5%AD%A6%EF%BC%8F%E7%B5%B1%E8%A8%88%E5%AD%A6%EF%BC%8F%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E3%81%AB%E3%81%8A%E3%81%91%E3%82%8B%E5%B9%BE%E4%BD%95%E5%B9%B3%E5%9D%87%EF%BC%88Geometric,%E3%81%AF%E7%9B%B8%E4%B9%97%E5%B9%B3%E5%9D%87%E3%81%A8%E3%82%82%E5%91%BC%E3%81%B0%E3%82%8C%E3%82%8B%E3%80%82]：平均伸び率(期間数√期間全体での伸び率)
- 調和平均^[https://atmarkit.itmedia.co.jp/ait/articles/2311/22/news040.html]：平均時速(全体距離/全体時間)

求めたいことの定義をよく考えると割と直感的に使い分けできる。

## 偏相関係数

# 6.連続型分布と標本分布
2級で扱わなかった連続分布を詳しく勉強することになります。覚えることが多くて気が滅入りますね。。

頻出の指数分布
いざとなったら導出出来そうですけど、覚えましょう。
https://bellcurve.jp/statistics/course/8009.html
https://avilen.co.jp/personal/knowledge-article/e-parameter-derivasion/

2変量、多変量正規分布
出るのは多分2変量の条件付き期待値、分散。
こちらは非常に導出が複雑なので、覚えてしまう他ない。
https://note.com/outlifest/n/n418af8f13892

ここら辺は全部覚える意味も無いし不可能なので、出題傾向見ながら必要な部分だけ覚えていきましょう。

# 極限定理、漸近理論
出題しないっぽいので、完璧にではなく言われれば何となく知ってるくらいで良いと思います。
数式と用語に気圧されるけれど、調べると簡単です。
https://note.com/outlifest/n/n7b2dd86ba173
https://qiita.com/ketchup1216/items/32533925cc7b0857c0ef

連続修正の分かりやすい解説が無かったので簡単に言うと、図のように棒の中心ではなく端から合計する感じです。
![](https://storage.googleapis.com/zenn-user-upload/774f71dd5f4c-20240605.jpeg)

デルタ法：$\sqrt{n}(f(\overline{X_{n}})-f(\mu))$の分布収束先を求める方法。
https://www.youtube.com/watch?v=Vmac6QC0owg

# 8.統計的推定の基礎
この章は桁違いに難しく、ボリューミーで重要です。
これまで何となく使ってきた用語をしっかりと意味を理解する必要があります。かなりややこしいですが、時間をかけて学んでいきましょう。

- 母数(パラメータ):母集団の特徴を表す母平均，母分散などの神のみぞ知る値。パラメータという命名が非常に分かりづらいので、パラメータ=母数であることに気を付けて読み進めましょう。

私たちは標本の情報から母数をどうにかして推定すること(統計的推定)で、母集団の特徴を知ろうとする訳ですね。

- 推定量:標本から母数を推定するアルゴリズム(関数)またはそれによって求められる値。例えば母平均の推定量には標本平均があり、母分散の推定量には標本分散があります。

- 統計量:母数の情報を含まない、標本の情報のみを利用したアルゴリズム(関数)またはそれによって求められる値。例えば母平均は含まないが、標本平均は含む。

推定量と統計量は曖昧なので分かりにくい。統計量+母数を推定するために使う=推定量と考えれば十分。実際、標本平均は統計量、推定量どちらでも使える。

このようにこの章では、簡単そうな名前でありながら厄介な用語があるので、よく意識しながら進めた方がいいと思います。

- 尤度関数(likelihood function):これも本来の定義としては曖昧なのですが、この章では、仮の母数を入力したら、その仮の母数が真の母数である尤もらしさを出力する関数L(θ)として、使われている。

- 最尤推定量:尤度関数を最大化する母数。最尤推定量は唯一ではないこともあるし、存在しないことさえある。

- 最尤法:尤度関数の最大となる母数を真の母数と推定する方法。例えば、母平均を求めたい時は、得られた標本が仮定した母平均（θ）により生成された確率 $f(X_{1};θ)$を全ての標本で掛け合わせることで求められる、もし母平均がθであった時に今の標本が得られる同時確率を尤度関数L(θ)として、最大となるθを母平均として推定する。
https://youtu.be/6XQJIQw-tUk?si=oWzGJKHQY5ONuNgS

最尤推定は非常に奥深いので、分からなくなったらWikipediaで確認することをおすすめする。
https://ja.m.wikipedia.org/wiki/%E6%9C%80%E5%B0%A4%E6%8E%A8%E5%AE%9A

- 順序統計量：標本を昇順に並べた統計量。1番目の順序統計量$X_{(1)}$は標本の最小値だし、n番目$X_{(n)}$なら最大値。同じように中央値なども順序統計量を使って表せる。
https://www.eeso.ges.kyoto-u.ac.jp/emm/materials/basic_stat/orderstat

- モーメント：モーメント法を学ぶためにモーメントの理解が必要だが、表記法がクソで本当に紛らわしい。a周りのn次のモーメントは$E[(X-a)^n]$と表すので、平均は0周りの1次のモーメントだし、分散は平均周りの2次のモーメントである。ここで酷いのが、0周りのn次のモーメントを$\mu_{n}$、平均周りのn次のモーメントを$\mu'_{n}$と表すこと。非常に紛らわしいので注意しましょう。
https://www.hello-statisticians.com/explain-terms-cat/moment1.html

- モーメント法：モーメントの連立方程式で、推定量を得る方法。
https://youtu.be/uoTmUlMDiq0?si=HAYG79PJRMBCv0VU

- 不偏性：その推定量が平均的に過大にも過小にも母数を推定しておらず、推定量の期待値が母数に等しいことを意味する。
https://bellcurve.jp/statistics/course/8612.html

- バイアス：母集団から抽出した標本の分布が、母集団の分布と比べて偶然ではないずれを起こしているとき、バイアスがあると言う。
https://bellcurve.jp/statistics/glossary/1382.html

バイアスとバリアンス(分散)のトレードオフを意識すると理解し易いと思います。
![](https://storage.googleapis.com/zenn-user-upload/c02a7f53f3fa-20240606.png =300x)
https://atmarkit.itmedia.co.jp/ait/articles/2009/09/news025.html

- バイアス-バリアンス分解：汎化誤差(平均二乗誤差など)の期待値をバイアス＋バリアンス＋ノイズの3つの和に分解すること。
https://ja.wikipedia.org/wiki/%E5%81%8F%E3%82%8A%E3%81%A8%E5%88%86%E6%95%A3

- ガウス=マルコフの定理：残差を最小にするように最小二乗法で求めた推定量が、最良線形不偏推定量になることを保証する定理。
https://ja.wikipedia.org/wiki/%E3%82%AC%E3%82%A6%E3%82%B9%EF%BC%9D%E3%83%9E%E3%83%AB%E3%82%B3%E3%83%95%E3%81%AE%E5%AE%9A%E7%90%86


- クラメール・ラオの不等式：不偏推定量の分散の下限(バイアスの期待値は0なので不偏推定量の下限)を知れる。
- クラメール・ラオの下限：クラメール・ラオの不等式によって求められる不偏推定量の分散の下限
- 有効推定量：クラメール・ラオの下限を満たす推定量。最も分散の小さい不偏推定量といえるので、優れた推定量と言える。
- フィッシャー情報量：フィッシャー情報量によって、クラメール・ラオの不等式を求められる。また、最尤推定量は対数尤度関数の母数偏微分の二乗の期待値なので、V[X]=E[X^2]-(E[X])^2が使える。https://www.youtube.com/watch?v=3yE5PrfNVrk

つまり、クラメール・ラオの不等式とフィッシャー情報量が重要なのは、推定量の優秀さ(有効推定量であるか)を調べられるからだと言える。


- 十分統計量：ある統計量(標本平均など)を定めると、母数(母平均など)を定めなくても、どのような標本が得られるかの確率が定まるような統計量(標本平均など)。
例えば、分散が既知の正規分布だと、標本平均が定まれば、母平均が定めなくても、ある程度どのような標本が得られるかは分かる。だが、最小値が定まっても、ある程度どのような標本が得られるかは分からない。
https://youtu.be/9i8b_zx8_kA?si=D5B9jtFkT0DA_ys9

- フィッシャー・ネイマンの分解定理：十分統計量であれば、今の標本が得られる尤度関数(同時確率分布)$L(θ)=f(x_{1},x_{2},\cdots,x_{n};θ)=f(x;θ)$を、母数の関係する関数と関係しない関数の積で表せる。
https://www.youtube.com/watch?v=sIKsbKO1Gmo

- 一致性：サンプルサイズが無限大になった時に、推定量が母数に一致すること。
https://bellcurve.jp/statistics/glossary/12813.html

不偏性と一致性の違いを確認しておきましょう。
https://bellcurve.jp/statistics/course/8612.html

- 漸近分布：標本サイズnを∞にした時に収束する分布。標本平均なら$(\mu,\sigma^2/n)$の正規分布。
- 漸近分散：漸近分布の分散。標本平均なら$\sigma^2/n$。
- 漸近有効性：推定量(標本平均など)の漸近分散が、クラメール・ラオの下限と一致していれば、推定量に漸近有効性があると言える。つまりnを∞にした時、推定量の分散が最小になる＝優れた推定量と言える。
- 漸近正規性：nを∞にした時、正規分布に分布収束すること。つまり、分散は0に収束するので偉い。

最尤推定量はの一致性、漸近有効性、漸近正規性を持つので、とてもいい推定量と思える。しかし、**不偏性を持つとは限らない。**
https://www.youtube.com/watch?v=oQfZjCO8Ja8
https://www.hello-statisticians.com/explain-terms-cat/point_estimation1.html#i-12

- ジャックナイフ法：不偏でない推定量(推定量の期待値が母数にならないのでバイアスは0にならない)を補正して、不偏推定量に近づけることができる。補正した推定量をジャックナイフ推定量という。アルゴリズムとしては、1つ標本を除いた部分標本の推定量を全ての標本を求め、その平均を推定量とするというシンプルなもの。https://qiita.com/nijigen_plot/items/cb7a51b4c42349a1d0a0

- リサンプリング法：ジャックナイフ法のように部分標本を用いて、推定精度を向上させる方法全般。ほかに有名なものとして、ブートストラップ法がある。

# 区間推定
2級の復習プラスアルファです。
母分散の比の検定:
https://bellcurve.jp/statistics/course/24270.html
多項分布の区間推定:母比率の区間推定に近い。
https://bellcurve.jp/statistics/course/9122.html
https://bellcurve.jp/statistics/course/26597.html
多項分布の差の区間推定:母比率の差の検定に近い。比率同士が独立でないので共分散が入ってくる。https://bellcurve.jp/statistics/course/18227.html
https://bellcurve.jp/statistics/course/18592.html
テキストのE[N1N2]=n(n-1)p1p2の解説をしてくれています。テクニカルなので自分で導出は相当面倒です。これは多項分布でしか成り立たないので注意が必要です。
https://learning-with-machine.hatenablog.com/entry/2021/05/27/220000


# 10.検定の基礎と検定法の導出
これも2級の復習プラスアルファです。
抜取検査のFP(合格品を不合格にする)が生産者危険、FN(不合格品を合格品にする)が消費者危険は分かりやすい良心的な命名で嬉しいですね。

# 11.正規分布に関する検定
またしても2級の復習プラスアルファです。
ほとんど復習なので、思い出しながら問題を解いて見てください。

# 12.一般の分布に関する検定法
ここも2級の復習プラスアルファですが、尤度比検定が新しく出てきます。
https://youtu.be/-C0JUkVrlHY?si=fRDExwYnS7eF5Xfg

# 13.ノンパラメトリック法
この章から新しいものが増えていきます。例に漏れず、初めて触れる人には読みずらいので、サイトを見てからワークブックで勉強する方が良いです。
https://bellcurve.jp/statistics/course/26258.html
ウィルコクソンの符号順位統計量の平均・分散
https://starpentagon.net/analytics/wilcoxon_signed_rank_mean_var/

# 14.マルコフ連鎖
行が今の状態を表し、列が今その状態である時の未来の状態確率であることを意識するといいです。
個人的には深く考えるより、解きながら覚えた方がいいと思います。
![](https://storage.googleapis.com/zenn-user-upload/2392684ee24c-20240611.png)
https://math-exploration.com/archives/212
https://manabitimes.jp/math/1060
https://manabitimes.jp/math/2757#5
例題の回答は圧倒的説明不足なので、次を参考にすると良いです。
https://note.com/ebikazuki/n/n4c1612b2fa94
https://youtu.be/ps_v34epZDM?si=--w7Pe3j7WR8LuKf

# 15.確率過程の基礎
これを見れば、確率過程がどう確率的なのか理解しやすいと思う。
ブラウン運動では平均は変わらず、tが増えていくにつれて、分散も増えていくことが分かる。
https://cdn-ak.f.st-hatena.com/images/fotolife/c/chaos_kiyono/20220628/20220628030127.gif
全体の解説
https://note.com/outlifest/n/n4a285406d35b
ブラウン運動、ランダムウォーク、ウィナー過程
https://chaos-kiyono.hatenablog.com/entry/2022/09/05/012341
ポアソン過程
ポアソン過程はウィナー過程と違い、上下動の幅ではなく発生頻度の幅が確率分布に従う。ウィナー過程では時間tが1増えるごとに、yが確率分布により生成された量分が増えていたが、ポアソン過程は時間tが確率分布により生成された量分増えたら、yが1増える。確率分布はウィナー過程は正規分布であったが、ポアソン過程は指数分布になる。
https://www.beginner-blogger.com/poisson-process/
複合ポアソン過程
複合ポアソン過程は合計の終端に確率変数が使われているので理解が難しいが、ポアソン過程のyの増加量をUkとして変更できるようにしたものだと考えればいい。
ポアソン過程では増加量は1なのでUk=1で複合ポアソン過程はポアソン過程とどういつになる。

# 16.重回帰分析
https://bellcurve.jp/statistics/course/9702.html

# 17.回帰診断法
初めて扱うものだが、ワークブックの説明だけでも問題を解けるようにはなるはず。
http://www.ner.takushoku-u.ac.jp/masano/class_material/waseda/keiryo/R20_reg3_BLUE.html
https://qiita.com/DeepMata/items/1657b3c463b9f5d2a39f#:~:text=%E3%81%AB%E3%81%AA%E3%82%8A%E3%81%BE%E3%81%99%E3%80%82-,Cook%E3%81%AE%E8%B7%9D%E9%9B%A2%E3%81%A8%E3%81%AF,%E3%81%AE%E6%94%B9%E5%96%84%E3%82%92%E8%A1%8C%E3%81%84%E3%81%BE%E3%81%99%E3%80%82
# 18.質的回帰
ロジスティクス回帰
必読。ワークブックだけじゃ絶対に例題を理解できない。
https://bellcurve.jp/statistics/course/26934.html
https://youtu.be/Xzwik2yGFig?si=R3htYti34_UkUP4C
https://youtu.be/8WGn8yEQ_x8?si=iaqv7eoXyyarZR8A
ロジスティクス変換は$1/1+e^{-1}$で覚えた方がいいかも知れません。
プロビットモデル
https://abcxyzonetwothree.hatenablog.com/entry/2018/11/24/143538

# 19.回帰分析その他
ワークブック説明不足。
全体像
https://note.com/outlifest/n/nb97236d661de
打ち切りモデルの尤度関数の導出
![](https://storage.googleapis.com/zenn-user-upload/e275f359f7b9-20240620.jpg)
![](https://storage.googleapis.com/zenn-user-upload/c44fa1d5f491-20240620.jpg)
<https://x.com/tak_math/status/1757681114045616258?t=5d67XChOG5Gd4fplAVEe_Q&s=19>
生存時間解析の全体像
https://youtu.be/oHsEblnENy8?si=e6qziixlPxpzfNym
https://ja.m.wikipedia.org/w/index.php?
圧倒的説明不足。ワークブックだけで理解できたら超能力者。生存時間解析は奥が深いので上手く区切りをつけることが大事です。
https://syleir.hatenablog.com/entry/2023/12/10/230619
title=%E7%94%9F%E5%AD%98%E5%88%86%E6%9E%90&diffonly=true#
https://necostat.hatenablog.jp/entry/2022/07/06/080239#%E3%83%8F%E3%82%B6%E3%83%BC%E3%83%89%E9%96%A2%E6%95%B0
https://syleir.hatenablog.com/entry/2024/01/12/195556
https://qiita.com/nakey_tdse/items/b40238599395653a7965
https://ja.m.wikipedia.org/wiki/%E6%AF%94%E4%BE%8B%E3%83%8F%E3%82%B6%E3%83%BC%E3%83%89%E3%83%A2%E3%83%87%E3%83%AB

ニューラルネットは割愛。
# 20.分散分析と実験計画法
ワークブックだと理屈がほとんど書いてないので、暗記頼りになりキツい。下記を見ながら練習問題を解くのがいいと思う。それでも解答も説明不足なので全部理解するのはかなり難しいので、そういう物だと理解した方がいいのかもしれない。
https://toketarou.com/quasi_1_cheatsheet/#toc21
https://bellcurve.jp/statistics/course/12744.html
https://bellcurve.jp/statistics/course/10006.html
https://youtu.be/-7rq1YfxiG4?si=v4iJOMAeVYjmO7N1
https://youtu.be/e6WjJYnsJZk?si=QTfOus4HZp9lEt_v
https://youtu.be/EH_pMI1nXV0?si=vfPw0WYHBTrqdHFc
https://youtu.be/WtQD2t5fr7k?si=pd4RFYeauioQ1wgX
https://youtu.be/_EX8dH_H2rI?si=GvqnjEIo-LAWJ11P
https://youtu.be/zO9J6Y3ve_s?si=pvo_PBhmRLDGXT0Y
https://youtu.be/QebP3V6jT60?si=MLDMZHB4bBhtQVhE
https://youtu.be/nsWFq_nrEm8?si=nODt4MOqoY6EPLUt

# 21.標本調査法
前章より遥かに分かり易い。問題を解きながら十分理解出来るはず。
https://toketarou.com/quasi_1_cheatsheet/#toc21

# 22.主成分分析
前節よりは難しい。
https://toketarou.com/quasi_1_cheatsheet/#toc22
https://youtu.be/bBEKlulWPH4?si=qXp9eMJiXMyQ1u8J
https://youtu.be/Etjrjx6iSsQ?si=NbRRhda-ohDQGI1z
https://qiita.com/LicaOka/items/1f4d1131af05fe30674e

# 23.判別分析
分類。難しいけど、掴みどころはあるので以下を読めば割と理解出来る。練習問題の解答は相変わらず説明不足。
https://toketarou.com/quasi_1_cheatsheet/#toc23
https://qiita.com/mtanaka-kumw/items/42edc102be5353dee618
https://qiita.com/pira/items/4c84399671be2cb598e4
https://qiita.com/mtanaka-kumw/items/7a380647b17f8a05a55c
https://youtu.be/OOvMLXRVZQM?si=X-jjIfuTUAMNz5Ry
https://youtu.be/zETzmJMea_8?si=feAOXfFkMJ8P983y
https://youtu.be/aLeUF52clTw?si=zLWCWIxLOsnc8MqQ
https://youtu.be/xI0KHBE1fvo?si=H1Pmfvn4qH6WO7OD
https://www.hello-statisticians.com/explain-books-cat/stat_workbook/stat_workbook_ch23.html#232
https://www.goodnalife.com/entry/2020/03/10/210434

# 24.クラスター分析
クラスタリング。
https://toketarou.com/quasi_1_cheatsheet/#toc24
https://bellcurve.jp/statistics/course/27155.html

# 25.因子分析・グラフィカルモデル
因子分析
https://youtu.be/neFRKLQnbpE?si=7xKg_M0S13ttTaNO
共通性の解説が不十分。
https://www.nttcoms.com/service/research/dataanalysis/factor-analysis/
https://istat.co.jp/ta_commentary/factor_analysis_02
https://youtu.be/5W4c7R1HvD8?si=QsKTHhE5pz9dAKtG
https://youtu.be/rJ2_hi-bq8k?si=ceYkipqQ8bJ1ZYQ7
https://ja.m.wikipedia.org/wiki/%E6%93%8D%E4%BD%9C%E5%A4%89%E6%95%B0%E6%B3%95
https://www.youtube.com/watch?v=hh_KPDZ1D2Y

# 26.その他の多変量解析手法
導出を理解する必要は無いので、以下を見て各手法の立ち位置と最低限の計算方法を覚えましょう。
https://toketarou.com/quasi_1_cheatsheet/#toc26
https://zenn.dev/pe/books/dd221cbc975950/viewer/af100b

# 27.時系列解析
細かい部分が難しい。
https://bellcurve.jp/statistics/course/12933.html
https://youtu.be/Fq73BS32a-8?si=WYELPLaVT1MGZjVq
https://tjo.hatenablog.com/entry/2013/07/04/190139
https://tjo.hatenablog.com/entry/2013/07/12/184704
https://messefor.hatenablog.com/entry/2020/08/14/191709#%E5%88%86%E6%95%A3
http://www.mi.u-tokyo.ac.jp/mds-oudan/lecture_document_2019_math7/time_series_analysis_2019.html
http://www.mi.u-tokyo.ac.jp/mds-oudan/lecture_document_2019_math7/%E6%99%82%E7%B3%BB%E5%88%97%E8%A7%A3%E6%9E%90%EF%BC%88%EF%BC%92%EF%BC%89_2019.pdf

# 28.分割表
ワークブックでは不十分なので、チートシートを見ながら勉強した方がいいです。
https://toketarou.com/quasi_1_cheatsheet/#toc28
https://bellcurve.jp/statistics/course/18127.html
https://bellcurve.jp/statistics/course/23950.html
https://bellcurve.jp/statistics/course/9496.html
https://bellcurve.jp/statistics/course/27075.html
https://bellcurve.jp/statistics/course/26781.html

# 29.不完全データの統計処理
https://best-biostatistics.com/summary/multiple_imputation.html
https://note.com/outlifest/n/nc6b7c016e695
# 31.ベイズ法
https://youtu.be/frHTMwRdMnA?si=w6QomjFnM-6EOW8p

# 32.シミュレーション
https://youtu.be/h2EURfZmcaw?si=4Nz5SxJ21kOiAQO6
https://manabitimes.jp/math/1160
https://aidiary.hatenablog.com/entry/20140712/1405165815
https://rayspace.xyz/CG/contents/montecarlo/
https://youtu.be/lRXvf4sb2m4?si=05icH-QvIIV8WWkX
問32.1(2)は解答が説明不足なのでこれを見るといい。
https://youtu.be/u2fNfHjsFeA?si=I7QXvO0b3q-oLIns
